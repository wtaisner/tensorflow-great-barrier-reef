{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "competition.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wtaisner/tensorflow-great-barrier-reef/blob/main/competition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import wandb\n",
        "except:\n",
        "    !pip install wandb\n",
        "    import wandb\n",
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_qievHg-wUI",
        "outputId": "0272e1ab-99bc-4450-863c-34ba46f14d4d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33map-wt\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "V6HmwJQ_Cmzv",
        "outputId": "cca7a70f-1545-4795-b018-e521d39e0392",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.io import read_image\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import ast\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "# this should probably be changed to something smart, right?\n",
        "KAGGLE_PATH_ANNOTATIONS = '/kaggle/input/tensorflow-great-barrier-reef/train.csv'\n",
        "KAGGLE_PATH_IMG_DIR = '/kaggle/input/tensorflow-great-barrier-reef/train_images/'\n",
        "LOCAL_PATH_ANNOTATIONS = 'data/train.csv'\n",
        "LOCAL_PATH_IMG_DIR = 'data/train_images/'\n",
        "COLAB_PATH_ANNOTATIONS = '/content/drive/MyDrive/data/train.csv'\n",
        "COLAB_PATH_IMG_DIR = '/content/drive/MyDrive/data/train_images/'\n",
        "\n",
        "wandb.config = {\n",
        "  \"learning_rate\": 0.001,\n",
        "  \"epochs\": 10,\n",
        "  \"batch_size\": 2,\n",
        "  \"momentum\": 0.9,\n",
        "  \"weight_decay\": 0.0005\n",
        "}"
      ],
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "papermill": {
          "duration": 1.961038,
          "end_time": "2022-01-14T11:54:15.753091",
          "exception": false,
          "start_time": "2022-01-14T11:54:13.792053",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2022-01-15T14:23:18.334933Z",
          "iopub.execute_input": "2022-01-15T14:23:18.335249Z",
          "iopub.status.idle": "2022-01-15T14:23:19.642124Z",
          "shell.execute_reply.started": "2022-01-15T14:23:18.335161Z",
          "shell.execute_reply": "2022-01-15T14:23:19.641445Z"
        },
        "trusted": true,
        "id": "jc9q8KQLAfkX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StarfishDataset(Dataset):\n",
        "    def __init__(self,\n",
        "                 annotations_file=COLAB_PATH_ANNOTATIONS,\n",
        "                 img_dir=COLAB_PATH_IMG_DIR\n",
        "                 ):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.annotated = self.img_labels[self.img_labels['annotations'] != '[]']  # get only annotated frames\n",
        "        self.img_dir = img_dir\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotated)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = read_image(os.path.join(self.img_dir, 'video_{}'.format(self.annotated.iloc[idx][0]),\n",
        "                                        '{}.jpg'.format(self.annotated.iloc[idx][2])))\n",
        "        min_image = image.min()\n",
        "        max_image = image.max()\n",
        "        # normalize image to 0-1 - required by torchvision\n",
        "        image -= min_image\n",
        "        image = torch.FloatTensor(image/max_image)\n",
        "        # print(image.shape) # image shape has to be [C, H, W], it is :)\n",
        "        labels = self.annotated.iloc[idx][-1]\n",
        "        labels = ast.literal_eval(labels)\n",
        "        coords = []\n",
        "        for parsed_label in labels:\n",
        "            x1, y1 = parsed_label['x'], parsed_label['y']\n",
        "            x2, y2 = x1+parsed_label['width'], y1+parsed_label['height']\n",
        "            coords.append([x1, y1, x2, y2])\n",
        "\n",
        "            # fig, ax = plt.subplots()\n",
        "            # ax.imshow(image.permute(1, 2, 0))\n",
        "            # rect = patches.Rectangle((x1, y1), parsed_label['width'], parsed_label['height'], linewidth=1, edgecolor='r', facecolor='none')\n",
        "            # ax.add_patch(rect)\n",
        "            # plt.show()\n",
        "\n",
        "        boxes = torch.FloatTensor(coords)\n",
        "        labels = torch.LongTensor([1 for _ in range(len(coords))]) # label has to be integer, since we have only one label I coded it as 1 for simplicity\n",
        "        # print(target[0].shape, target[1].shape)\n",
        "        return image, boxes, labels\n",
        "\n",
        "# dataset = StarfishDataset()\n",
        "# dataset.__getitem__(0)\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-01-15T14:23:19.643849Z",
          "iopub.execute_input": "2022-01-15T14:23:19.644532Z",
          "iopub.status.idle": "2022-01-15T14:23:19.856879Z",
          "shell.execute_reply.started": "2022-01-15T14:23:19.644491Z",
          "shell.execute_reply": "2022-01-15T14:23:19.856050Z"
        },
        "trusted": true,
        "id": "tg35LhdxAfkd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    targets = []\n",
        "    images = []\n",
        "    for imgs, boxes, labels in batch:\n",
        "        images.append(imgs)\n",
        "        d = {}\n",
        "        d['boxes'] = boxes\n",
        "        d['labels'] = labels\n",
        "        targets.append(d)\n",
        "    return images, targets"
      ],
      "metadata": {
        "id": "UYRK09bPRfII"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)\n",
        "\n",
        "dataset = StarfishDataset()\n",
        "train_size = int(0.3 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# extract only small part of the data for faster learning / testing process\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "test_size = len(train_dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(train_dataset, [train_size, test_size])\n",
        "\n",
        "\n",
        "print('Train dataset: {} instances, test dataset: {}'.format(len(train_dataset), len(test_dataset)))\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset, batch_size=wandb.config['batch_size'], shuffle=False, num_workers=1, collate_fn = collate_fn)\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset, batch_size=wandb.config['batch_size'], shuffle=False, num_workers=1,  collate_fn = collate_fn)\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "cpu = torch.device('cpu')\n",
        "print('Used device: {}'.format(device))\n",
        "\n",
        "num_classes = 2  # starfish and not starfish I guess\n",
        "\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "model.to(device)\n",
        "\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=wandb.config['learning_rate'], momentum=wandb.config['momentum'], weight_decay=wandb.config['weight_decay'])\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-01-15T14:25:03.794536Z",
          "iopub.execute_input": "2022-01-15T14:25:03.794811Z",
          "iopub.status.idle": "2022-01-15T14:25:04.483121Z",
          "shell.execute_reply.started": "2022-01-15T14:25:03.794780Z",
          "shell.execute_reply": "2022-01-15T14:25:04.482306Z"
        },
        "trusted": true,
        "id": "wkGu_Sh6Afkh",
        "outputId": "98fdbe8d-2fb8-4152-d7a2-35eb18248a3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset: 1180 instances, test dataset: 295\n",
            "Used device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# images, boxes = torch.rand(4, 3, 600, 1200), torch.rand(4, 11, 4)\n",
        "# labels = torch.randint(1, 91, (4, 11))\n",
        "# images = list(image for image in images)\n",
        "# targets = []\n",
        "# for i in range(len(images)):\n",
        "#     d = {}\n",
        "#     d['boxes'] = boxes[i]\n",
        "#     d['labels'] = labels[i]\n",
        "#     targets.append(d)\n",
        "\n",
        "# print('Images {} \\n Boxes {} \\n labels {} \\n targets {} \\n'.format(len(images), boxes.shape, labels.shape, targets))"
      ],
      "metadata": {
        "id": "GRxcE-ZAP2xP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pytorch.org/vision/stable/models.html#runtime-characteristics see Faster R-CNN for the details of this model, what it requires, returns, etc\n",
        "\n",
        "# https://github.com/pytorch/vision/blob/main/references/detection/engine.py probably see training and eval loops here\n",
        "\n",
        "wandb.init(project=\"great-barrier-reef\", entity=\"ap-wt\", config = wandb.config)\n",
        "\n",
        "for e in tqdm(range(wandb.config['epochs'])):\n",
        "# for e in tqdm(range(2)):\n",
        "    print('\\n')\n",
        "    \n",
        "    model.train()\n",
        "\n",
        "    for idx, (images, targets) in enumerate(train_dataloader):\n",
        "\n",
        "        images = list(image.to(device) for image in images)\n",
        "\n",
        "        for d in targets:\n",
        "            d['boxes'] = d['boxes'].to(device)\n",
        "            d['labels'] = d['labels'].to(device)\n",
        "\n",
        "        loss_dict = model(images, targets)\n",
        "        loss = sum(loss for loss in loss_dict.values())\n",
        "        wandb.log({'train_loss':loss})\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    model.eval()\n",
        "    print('Reached eval')\n",
        "    with torch.no_grad():\n",
        "        groundtruth, predictions = None, None\n",
        "        for idx, (images, targets) in enumerate(test_dataloader):\n",
        "\n",
        "            images = list(image.to(device) for image in images)\n",
        "            predictions = model(images)\n",
        "            outputs = [{k: v.to(cpu) for k, v in t.items()} for t in predictions]\n",
        "            # TODO: add some comparison with 'targets' perhaps\n",
        "            if idx % 50 == 0:\n",
        "                print(outputs)\n",
        "            wandb.log({\"adam\": outputs})\n",
        "\n",
        "    optimizer.step()\n",
        "wandb.finish()"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2022-01-15T14:25:07.542207Z",
          "iopub.execute_input": "2022-01-15T14:25:07.542717Z",
          "iopub.status.idle": "2022-01-15T14:27:34.233257Z",
          "shell.execute_reply.started": "2022-01-15T14:25:07.542683Z",
          "shell.execute_reply": "2022-01-15T14:27:34.232060Z"
        },
        "trusted": true,
        "id": "IZq9ZxqRAfkn",
        "outputId": "7ab7ecb3-e540-485e-c6c9-0288afeb0ec1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33map-wt\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/ap-wt/great-barrier-reef/runs/1bcbvs8t\" target=\"_blank\">different-salad-19</a></strong> to <a href=\"https://wandb.ai/ap-wt/great-barrier-reef\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reached eval\n",
            "[{'boxes': tensor([[ 597.3156,  378.6286,  663.7199,  439.7719],\n",
            "        [ 790.4837,  611.1317,  874.0908,  681.3749],\n",
            "        [ 497.7653,  391.9684,  560.9460,  459.7655],\n",
            "        [ 195.9283,  208.9145,  246.7803,  250.2139],\n",
            "        [ 547.5464,  339.0098,  608.0395,  393.8109],\n",
            "        [ 234.7136,  337.5928,  294.2419,  391.3565],\n",
            "        [ 302.3225,  406.7838,  340.5309,  447.2247],\n",
            "        [ 577.9064,  554.4933,  633.1340,  623.2035],\n",
            "        [ 519.1411,  340.0183,  598.9832,  405.3338],\n",
            "        [ 451.2263,   94.3412,  492.9230,  137.1499],\n",
            "        [ 501.3882,  356.9796,  578.8117,  465.8529],\n",
            "        [ 325.3591,  554.5240,  397.9320,  628.4894],\n",
            "        [ 510.0660,  346.2499,  565.0208,  400.6040],\n",
            "        [ 402.8376,   61.2239,  442.3608,   97.9702],\n",
            "        [ 202.4045,  205.9955,  247.3283,  233.1169],\n",
            "        [ 534.7263,  338.5306,  608.8254,  446.9872],\n",
            "        [ 343.2345,  568.6543,  390.0980,  615.6118],\n",
            "        [ 531.4572,  395.3956,  561.9553,  447.1858],\n",
            "        [ 134.0036,  222.9003,  170.2631,  266.5438],\n",
            "        [ 218.8794,  328.4506,  309.7557,  405.8720],\n",
            "        [1201.5746,  214.4951, 1245.9481,  258.1843],\n",
            "        [ 594.1520,  566.3197,  638.3249,  609.9492],\n",
            "        [ 240.7812,  330.2733,  284.3058,  373.6159],\n",
            "        [ 303.9521,  529.7261,  404.7682,  643.3105],\n",
            "        [ 466.2751,  389.2460,  573.8233,  469.9750],\n",
            "        [1085.2411,  527.6204, 1157.3300,  591.5397],\n",
            "        [ 575.9628,  537.3734,  663.7772,  651.9514],\n",
            "        [ 574.7698,  380.6992,  691.1123,  449.6222],\n",
            "        [ 195.2811,  307.8427,  236.6217,  344.5368],\n",
            "        [ 177.7836,  196.4015,  261.6793,  265.0811],\n",
            "        [ 359.2030,  562.9197,  403.4644,  608.3233],\n",
            "        [  64.3134,  531.3251,  110.6841,  585.6220],\n",
            "        [1204.2369,  204.2731, 1271.5630,  262.6485],\n",
            "        [1150.6207,   77.7062, 1182.4585,  112.6734],\n",
            "        [ 259.9286,  444.8673,  296.0370,  473.8360],\n",
            "        [  98.5208,  531.5018,  150.5624,  580.7181],\n",
            "        [ 512.8516,  363.3018,  639.6390,  445.8714],\n",
            "        [ 312.3498,  126.4849,  342.6230,  148.9082],\n",
            "        [ 163.2498,  250.9816,  201.3558,  281.8004],\n",
            "        [ 296.6522,  410.4586,  359.4484,  483.3022],\n",
            "        [ 856.3030,  292.1475,  914.9925,  339.7866],\n",
            "        [ 490.7186,  386.9160,  650.3365,  464.2664],\n",
            "        [1043.5769,  107.7582, 1110.3824,  151.0683],\n",
            "        [ 227.1685,  363.6333,  275.7549,  403.4879],\n",
            "        [ 827.7838,  641.7960,  875.6757,  679.9540],\n",
            "        [  19.3532,  599.0128,   98.8430,  679.9828],\n",
            "        [ 535.2466,  173.8030,  574.0308,  227.6010],\n",
            "        [ 270.3071,  399.1685,  378.2632,  465.3897],\n",
            "        [ 649.8134,  612.3358,  721.4063,  680.1351]]), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1]), 'scores': tensor([0.9615, 0.9433, 0.9176, 0.9128, 0.8985, 0.8490, 0.7326, 0.5937, 0.5515,\n",
            "        0.5441, 0.5245, 0.4282, 0.4138, 0.3497, 0.2882, 0.2714, 0.2537, 0.2523,\n",
            "        0.2458, 0.2390, 0.2357, 0.2136, 0.2062, 0.1795, 0.1642, 0.1636, 0.1519,\n",
            "        0.1455, 0.1343, 0.1271, 0.1175, 0.1099, 0.1096, 0.1064, 0.0905, 0.0904,\n",
            "        0.0851, 0.0788, 0.0758, 0.0728, 0.0719, 0.0630, 0.0615, 0.0571, 0.0568,\n",
            "        0.0522, 0.0520, 0.0516, 0.0502])}, {'boxes': tensor([[ 18.2078, 289.8308,  91.6865, 327.9781],\n",
            "        [ 47.4276, 286.5166,  91.4200, 321.6300],\n",
            "        [  6.4280, 279.7438, 103.3644, 343.0833],\n",
            "        [576.2639, 468.6728, 636.6864, 522.8239],\n",
            "        [ 74.7763, 171.6454, 133.6300, 225.1216],\n",
            "        [ 18.8741, 288.8262,  59.3202, 321.2093],\n",
            "        [396.7965, 415.2513, 434.8333, 454.9131],\n",
            "        [ 57.0522, 295.4056,  95.1360, 327.4532],\n",
            "        [ 95.6479, 183.6776, 138.0060, 224.2262],\n",
            "        [ 53.9905, 285.5552,  91.0623, 307.4811],\n",
            "        [379.7635, 433.6304, 413.5786, 465.7991],\n",
            "        [595.4017, 480.8987, 642.1915, 520.9349],\n",
            "        [ 48.9240, 248.0535, 104.1005, 290.8790],\n",
            "        [445.6200, 140.9636, 483.2633, 175.4655]]), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'scores': tensor([0.8241, 0.2547, 0.2511, 0.1517, 0.1406, 0.1012, 0.0939, 0.0815, 0.0718,\n",
            "        0.0647, 0.0618, 0.0599, 0.0586, 0.0513])}]\n",
            "[{'boxes': tensor([[1.9929e+02, 5.6711e+02, 2.6294e+02, 6.4192e+02],\n",
            "        [3.3648e+02, 3.9534e+02, 3.7933e+02, 4.3669e+02],\n",
            "        [9.9817e-01, 3.1917e+02, 3.8036e+01, 3.7724e+02],\n",
            "        [1.6143e+02, 4.1022e+02, 2.0815e+02, 4.5651e+02],\n",
            "        [5.6256e+02, 3.2651e+02, 6.0765e+02, 3.8599e+02],\n",
            "        [2.2717e+00, 3.2648e+02, 3.4411e+01, 3.5361e+02],\n",
            "        [1.1017e+03, 4.0511e+01, 1.1637e+03, 9.1637e+01],\n",
            "        [1.1313e+03, 2.4079e+02, 1.1857e+03, 2.9376e+02],\n",
            "        [3.9351e+02, 2.8257e+02, 4.3275e+02, 3.1825e+02],\n",
            "        [7.6985e+02, 1.1022e+02, 7.9710e+02, 1.4652e+02],\n",
            "        [8.1495e+02, 5.6938e+00, 8.5706e+02, 4.0271e+01],\n",
            "        [1.0071e+03, 9.9263e+01, 1.0555e+03, 1.7450e+02],\n",
            "        [6.7891e+02, 6.0952e+02, 7.1746e+02, 6.3968e+02],\n",
            "        [1.5729e+00, 3.0277e+02, 3.2885e+01, 3.4997e+02],\n",
            "        [2.6569e+02, 4.9348e+02, 3.0093e+02, 5.3147e+02],\n",
            "        [3.5478e+02, 4.3209e+02, 4.0856e+02, 4.8551e+02],\n",
            "        [1.0177e+00, 2.3742e+02, 3.9704e+01, 4.2371e+02],\n",
            "        [4.5298e+02, 4.9365e+02, 5.0112e+02, 5.3452e+02],\n",
            "        [2.6522e+02, 2.1057e+02, 3.0189e+02, 2.4274e+02],\n",
            "        [6.8045e+01, 2.6990e+02, 1.4950e+02, 3.2282e+02],\n",
            "        [1.0404e+03, 3.2266e+02, 1.1061e+03, 3.6598e+02],\n",
            "        [3.0840e+02, 6.0381e+02, 3.4980e+02, 6.4529e+02],\n",
            "        [9.2179e+02, 2.6417e+02, 9.8714e+02, 3.2474e+02],\n",
            "        [1.9098e+02, 1.5296e+00, 2.3668e+02, 4.0942e+01],\n",
            "        [6.4693e-01, 5.0467e+02, 4.2026e+01, 5.5251e+02],\n",
            "        [2.9811e+01, 3.4232e+02, 7.2889e+01, 3.7501e+02]]), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1]), 'scores': tensor([0.7301, 0.7106, 0.4871, 0.4517, 0.3742, 0.2364, 0.1899, 0.1771, 0.1555,\n",
            "        0.1459, 0.1457, 0.1327, 0.1215, 0.0983, 0.0933, 0.0817, 0.0787, 0.0750,\n",
            "        0.0674, 0.0671, 0.0662, 0.0620, 0.0596, 0.0594, 0.0582, 0.0542])}, {'boxes': tensor([[698.8805, 257.8170, 742.7089, 301.2962],\n",
            "        [243.3908, 583.5091, 299.6488, 624.5056],\n",
            "        [424.8294, 642.9147, 473.7747, 696.3383],\n",
            "        [692.7292, 266.4732, 758.0961, 310.6186],\n",
            "        [214.0952,   0.0000, 247.6090,  25.1439],\n",
            "        [560.9838, 403.8716, 605.3907, 445.7343],\n",
            "        [ 28.6191, 476.3383,  55.5181, 524.9891],\n",
            "        [779.5782,   1.2137, 829.3285,  37.4202],\n",
            "        [772.4388, 201.0084, 812.3802, 237.0280],\n",
            "        [341.3035,  46.4517, 383.7155,  83.0209]]), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'scores': tensor([0.8015, 0.1719, 0.1557, 0.1104, 0.1028, 0.0938, 0.0594, 0.0587, 0.0583,\n",
            "        0.0566])}]\n",
            "[{'boxes': tensor([[ 330.4592,  168.2183,  379.8716,  216.4835],\n",
            "        [ 188.1972,  143.1529,  220.2726,  187.3175],\n",
            "        [ 971.4391,  337.3356, 1049.3046,  411.0348],\n",
            "        [ 781.2803,  248.3236,  818.9728,  285.0155],\n",
            "        [ 106.3684,  222.7983,  128.1201,  257.7278],\n",
            "        [ 188.6646,  421.3716,  238.4290,  501.9534],\n",
            "        [1019.0694,   19.2546, 1062.0634,   50.2373],\n",
            "        [ 884.8813,  117.3559,  926.0949,  158.6325],\n",
            "        [ 746.3779,  228.2458,  803.6856,  277.3698],\n",
            "        [  89.8371,  212.9918,  140.2520,  258.6011],\n",
            "        [ 366.7373,  143.9664,  401.8697,  169.8588],\n",
            "        [ 103.2868,  227.9669,  137.5089,  251.0437],\n",
            "        [ 630.7653,   67.8176,  664.6659,   96.7777],\n",
            "        [ 119.9951,  151.7270,  170.7420,  198.6460],\n",
            "        [ 443.8257,  420.8234,  499.4215,  452.3153],\n",
            "        [ 150.3032,  143.4171,  191.2233,  166.7166],\n",
            "        [ 105.5378,  218.0752,  154.5455,  260.9584],\n",
            "        [  74.6770,  215.0297,  123.5804,  260.4828]]), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'scores': tensor([0.6099, 0.2208, 0.1673, 0.1400, 0.1391, 0.1252, 0.1220, 0.1020, 0.0997,\n",
            "        0.0881, 0.0860, 0.0846, 0.0832, 0.0655, 0.0626, 0.0598, 0.0577, 0.0541])}, {'boxes': tensor([[303.2551, 403.8525, 348.8088, 444.9272],\n",
            "        [429.5711, 110.1406, 462.9161, 143.8262],\n",
            "        [260.5772, 524.2730, 293.6378, 560.8237],\n",
            "        [ 67.3247, 323.2853,  98.3780, 350.9930],\n",
            "        [195.3817, 657.4366, 237.6494, 715.7625],\n",
            "        [354.6285, 135.5154, 406.7369, 181.0145],\n",
            "        [353.0858, 527.8277, 398.1147, 605.3810],\n",
            "        [329.3830, 282.3416, 360.9814, 313.9440],\n",
            "        [627.7413, 203.7391, 664.8572, 242.6888],\n",
            "        [357.2475, 150.0108, 399.4629, 176.8752],\n",
            "        [230.4478, 512.3819, 266.8470, 543.1315],\n",
            "        [798.4789, 677.4198, 835.9332, 716.8671],\n",
            "        [717.3129, 180.8352, 764.6704, 212.6190],\n",
            "        [152.5361, 393.6539, 186.5533, 423.2336],\n",
            "        [428.1227, 102.8381, 478.3749, 147.6669],\n",
            "        [223.5462, 506.8105, 276.8066, 551.3896],\n",
            "        [361.2545, 555.7838, 398.9838, 600.3175]]), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'scores': tensor([0.4268, 0.1791, 0.1753, 0.1608, 0.1587, 0.1369, 0.1369, 0.0928, 0.0890,\n",
            "        0.0875, 0.0760, 0.0723, 0.0617, 0.0606, 0.0587, 0.0586, 0.0560])}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|â–ˆ         | 1/10 [06:37<59:37, 397.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qxM4AnVQTjHs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}