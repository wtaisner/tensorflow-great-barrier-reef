{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "colab": {
   "name": "competition.ipynb",
   "provenance": []
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2da650037a8f45b58d61466e12a3caa0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "VBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "VBoxView",
      "_dom_classes": [],
      "_model_name": "VBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_5fe1ee4bf2b240328dc7708ea6cb6825",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_5813189d3f6f4ec08e346b0c9621610f",
       "IPY_MODEL_d29a1b5a093447a9a5ae8372baa31af0"
      ]
     }
    },
    "5fe1ee4bf2b240328dc7708ea6cb6825": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "5813189d3f6f4ec08e346b0c9621610f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "LabelModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "LabelView",
      "style": "IPY_MODEL_4398a0023a1248e983984da8252f8927",
      "_dom_classes": [],
      "description": "",
      "_model_name": "LabelModel",
      "placeholder": "â€‹",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_0478f705c134463db5fbdaa0b4f210b4"
     }
    },
    "d29a1b5a093447a9a5ae8372baa31af0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_452f6bc30d5f4bc1b16e20f123c052b0",
      "_dom_classes": [],
      "description": "",
      "_model_name": "FloatProgressModel",
      "bar_style": "",
      "max": 1,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 1,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_6a362696bd5643bb988c414ad9b9a512"
     }
    },
    "4398a0023a1248e983984da8252f8927": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "0478f705c134463db5fbdaa0b4f210b4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "452f6bc30d5f4bc1b16e20f123c052b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "6a362696bd5643bb988c414ad9b9a512": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    }
   }
  }
 },
 "nbformat_minor": 0,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "try:\n",
    "    import wandb\n",
    "except:\n",
    "    !pip install wandb\n",
    "    import wandb\n",
    "!wandb login"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v_qievHg-wUI",
    "outputId": "b012456d-8670-4200-8454-e9f7c102f86d"
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: You can find your API key in your browser here: https://wandb.ai/authorize\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \r\n",
      "Aborted!\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "try:\n",
    "    import torchmetrics\n",
    "except:\n",
    "    !pip install torchmetrics\n",
    "    import torchmetrics"
   ],
   "metadata": {
    "id": "eQVkm8cT7AzV"
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "V6HmwJQ_Cmzv",
    "outputId": "8b6776ed-6870-4d8e-ce4e-ec6465605c81",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 27,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import torchvision\n",
    "import ast\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchmetrics.detection.map import MeanAveragePrecision\n",
    "\n",
    "\n",
    "# this should probably be changed to something smart, right?\n",
    "KAGGLE_PATH_ANNOTATIONS = '/kaggle/input/tensorflow-great-barrier-reef/train.csv'\n",
    "KAGGLE_PATH_IMG_DIR = '/kaggle/input/tensorflow-great-barrier-reef/train_images/'\n",
    "LOCAL_PATH_ANNOTATIONS = 'data/train.csv'\n",
    "LOCAL_PATH_IMG_DIR = 'data/train_images/'\n",
    "COLAB_PATH_ANNOTATIONS = '/content/drive/MyDrive/data/train.csv'\n",
    "COLAB_PATH_IMG_DIR = '/content/drive/MyDrive/data/train_images/'\n",
    "\n",
    "wandb.config = {\n",
    "  \"learning_rate\": 0.001,\n",
    "  \"epochs\": 2,\n",
    "  \"batch_size\": 2,\n",
    "  \"momentum\": 0.9,\n",
    "  \"weight_decay\": 0.0005, \n",
    "  \"confidence_threshold\": 0.7 # save a bounding box if model returned confidence above this threshold\n",
    "}"
   ],
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 1.961038,
     "end_time": "2022-01-14T11:54:15.753091",
     "exception": false,
     "start_time": "2022-01-14T11:54:13.792053",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2022-01-15T14:23:18.334933Z",
     "iopub.execute_input": "2022-01-15T14:23:18.335249Z",
     "iopub.status.idle": "2022-01-15T14:23:19.642124Z",
     "shell.execute_reply.started": "2022-01-15T14:23:18.335161Z",
     "shell.execute_reply": "2022-01-15T14:23:19.641445Z"
    },
    "trusted": true,
    "id": "jc9q8KQLAfkX"
   },
   "execution_count": 54,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class StarfishDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 annotations_file=COLAB_PATH_ANNOTATIONS,\n",
    "                 img_dir=COLAB_PATH_IMG_DIR\n",
    "                 ):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.annotated = self.img_labels[self.img_labels['annotations'] != '[]']  # get only annotated frames\n",
    "        self.img_dir = img_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotated)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = read_image(os.path.join(self.img_dir, 'video_{}'.format(self.annotated.iloc[idx][0]),\n",
    "                                        '{}.jpg'.format(self.annotated.iloc[idx][2])))\n",
    "        min_image = image.min()\n",
    "        max_image = image.max()\n",
    "        # normalize image to 0-1 - required by torchvision\n",
    "        image -= min_image\n",
    "        image = torch.FloatTensor(image/max_image)\n",
    "        labels = self.annotated.iloc[idx][-1]\n",
    "        labels = ast.literal_eval(labels)\n",
    "        coords = []\n",
    "        for parsed_label in labels:\n",
    "            x1, y1 = parsed_label['x'], parsed_label['y']\n",
    "            x2, y2 = x1+parsed_label['width'], y1+parsed_label['height']\n",
    "            coords.append([x1, y1, x2, y2])\n",
    "\n",
    "        boxes = torch.FloatTensor(coords)\n",
    "        labels = torch.LongTensor([1 for _ in range(len(coords))]) # label has to be integer, since we have only one label I coded it as 1 for simplicity\n",
    "        return image, boxes, labels\n",
    "\n",
    "# dataset = StarfishDataset()\n",
    "# dataset.__getitem__(0)\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-01-15T14:23:19.643849Z",
     "iopub.execute_input": "2022-01-15T14:23:19.644532Z",
     "iopub.status.idle": "2022-01-15T14:23:19.856879Z",
     "shell.execute_reply.started": "2022-01-15T14:23:19.644491Z",
     "shell.execute_reply": "2022-01-15T14:23:19.856050Z"
    },
    "trusted": true,
    "id": "tg35LhdxAfkd"
   },
   "execution_count": 55,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def collate_fn(batch):\n",
    "    targets = []\n",
    "    images = []\n",
    "    for imgs, boxes, labels in batch:\n",
    "        images.append(imgs)\n",
    "        d = {}\n",
    "        d['boxes'] = boxes\n",
    "        d['labels'] = labels\n",
    "        targets.append(d)\n",
    "    return images, targets\n",
    "\n",
    "def slice_output(output: dict, confidence_threshold: float = wandb.config['confidence_threshold']) -> dict:\n",
    "    \"\"\"\n",
    "    this method is responsible for validating models output w.r.t confidence_threshold defined above.\n",
    "    It accepts an output dictionary from model, namely {'boxes':[], 'labels':[], 'scores':[]}\n",
    "    It returns a dictionary sliced to items with score above confidence_threshold\n",
    "    \"\"\"\n",
    "\n",
    "    num_valid_elements = np.sum(np.array(output['scores']) >= confidence_threshold)\n",
    "    # temporary option to make sure, that it returns at least one element, although it should probably be fixed,\n",
    "    # should there be any frames where there is no starfish\n",
    "    if num_valid_elements == 0:\n",
    "        num_valid_elements = 1\n",
    "    res = {}\n",
    "    for key, value in output.items():\n",
    "        res[key] = value[:num_valid_elements]\n",
    "    return res"
   ],
   "metadata": {
    "id": "UYRK09bPRfII",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "43e732d1-fcfe-43f8-c703-f18c3442c43d"
   },
   "execution_count": 56,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'boxes': [[601.2649, 390.7638, 653.7231, 436.5513],\n",
       "  [541.5198, 465.4016, 588.3859, 511.2046],\n",
       "  [426.1378, 628.664, 485.297, 695.2532]],\n",
       " 'labels': [1, 1, 1],\n",
       " 'scores': [0.8809, 0.8313, 0.7175]}"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "torch.manual_seed(23)\n",
    "\n",
    "# IF YOU WANT TO RUN PROPER MODEL LEARNING, MAKE SURE TO CHANGE DATASET SIZES\n",
    "\n",
    "dataset = StarfishDataset()\n",
    "train_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# extract only small part of the data for faster learning / testing process\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "test_size = len(train_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(train_dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "print('Train dataset: {} instances, test dataset: {}'.format(len(train_dataset), len(test_dataset)))\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=wandb.config['batch_size'], shuffle=False, num_workers=1, collate_fn = collate_fn)\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=wandb.config['batch_size'], shuffle=False, num_workers=1,  collate_fn = collate_fn)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "cpu = torch.device('cpu')\n",
    "print('Used device: {}'.format(device))\n",
    "\n",
    "num_classes = 2  # starfish and not starfish I guess\n",
    "\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "model.to(device)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=wandb.config['learning_rate'], momentum=wandb.config['momentum'], weight_decay=wandb.config['weight_decay'])\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-01-15T14:25:03.794536Z",
     "iopub.execute_input": "2022-01-15T14:25:03.794811Z",
     "iopub.status.idle": "2022-01-15T14:25:04.483121Z",
     "shell.execute_reply.started": "2022-01-15T14:25:03.794780Z",
     "shell.execute_reply": "2022-01-15T14:25:04.482306Z"
    },
    "trusted": true,
    "id": "wkGu_Sh6Afkh",
    "outputId": "087194ba-af0b-47ac-e3c0-ef891fa997a6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 57,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train dataset: 392 instances, test dataset: 99\n",
      "Used device: cuda\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# https://pytorch.org/vision/stable/models.html#runtime-characteristics see Faster R-CNN for the details of this model, what it requires, returns, etc\n",
    "\n",
    "# https://github.com/pytorch/vision/blob/main/references/detection/engine.py probably see training and eval loops here\n",
    "\n",
    "wandb.init(project=\"great-barrier-reef\", entity=\"ap-wt\", config = wandb.config)\n",
    "for e in tqdm(range(wandb.config['epochs'])):\n",
    "    print('\\n')\n",
    "        \n",
    "    model.train()\n",
    "\n",
    "    for idx, (images, targets) in enumerate(train_dataloader):\n",
    "\n",
    "        images = list(image.to(device) for image in images)\n",
    "\n",
    "        for d in targets:\n",
    "            d['boxes'] = d['boxes'].to(device)\n",
    "            d['labels'] = d['labels'].to(device)\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "        loss = sum(loss for loss in loss_dict.values())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, (images, targets) in enumerate(test_dataloader):\n",
    "\n",
    "            images = list(image.to(device) for image in images)\n",
    "            predictions = model(images)\n",
    "            outputs = [{k: v.to(cpu) for k, v in t.items()} for t in predictions]\n",
    "\n",
    "            # TODO: add some comparison with 'targets' perhaps\n",
    "            # TODO: any loss functions that is more reliable than this ? idk\n",
    "            outputs = [slice_output(out) for out in outputs]\n",
    "            metric = MeanAveragePrecision()\n",
    "            metric.update(outputs, targets)\n",
    "            metrics = metric.compute()\n",
    "            if idx % 100 == 0:\n",
    "                wandb.log({'MAP':metrics['map'], 'MAR_1':metrics['mar_1']})\n",
    "        \n",
    "\n",
    "\n",
    "    optimizer.step()\n",
    "wandb.finish()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2022-01-15T14:25:07.542207Z",
     "iopub.execute_input": "2022-01-15T14:25:07.542717Z",
     "iopub.status.idle": "2022-01-15T14:27:34.233257Z",
     "shell.execute_reply.started": "2022-01-15T14:25:07.542683Z",
     "shell.execute_reply": "2022-01-15T14:27:34.232060Z"
    },
    "trusted": true,
    "id": "IZq9ZxqRAfkn",
    "outputId": "8fde52ed-24a2-49e6-d8fb-fc7f0d156751",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318,
     "referenced_widgets": [
      "2da650037a8f45b58d61466e12a3caa0",
      "5fe1ee4bf2b240328dc7708ea6cb6825",
      "5813189d3f6f4ec08e346b0c9621610f",
      "d29a1b5a093447a9a5ae8372baa31af0",
      "4398a0023a1248e983984da8252f8927",
      "0478f705c134463db5fbdaa0b4f210b4",
      "452f6bc30d5f4bc1b16e20f123c052b0",
      "6a362696bd5643bb988c414ad9b9a512"
     ]
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/FastRCNN.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}