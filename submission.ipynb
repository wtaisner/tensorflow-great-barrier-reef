{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a63162ae",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-01-19T10:32:25.158050Z",
     "iopub.status.busy": "2022-01-19T10:32:25.144134Z",
     "iopub.status.idle": "2022-01-19T10:32:34.343811Z",
     "shell.execute_reply": "2022-01-19T10:32:34.343070Z",
     "shell.execute_reply.started": "2022-01-19T10:31:09.253317Z"
    },
    "papermill": {
     "duration": 9.209229,
     "end_time": "2022-01-19T10:32:34.344043",
     "exception": false,
     "start_time": "2022-01-19T10:32:25.134814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import torchvision\n",
    "import torch\n",
    "\n",
    "def slice_output(output: dict, confidence_threshold: float = 0.7) -> dict:\n",
    "    \"\"\"\n",
    "    this method is responsible for validating models output w.r.t confidence_threshold defined above.\n",
    "    It accepts an output dictionary from model, namely {'boxes':[], 'labels':[], 'scores':[]}\n",
    "    It returns a dictionary sliced to items with score above confidence_threshold\n",
    "    \"\"\"\n",
    "\n",
    "    num_valid_elements = np.sum(np.array(output['scores']) >= confidence_threshold)\n",
    "    # temporary option to make sure, that it returns at least one element, although it should probably be fixed, \n",
    "    # should there be any frames where there is no starfish\n",
    "    if num_valid_elements == 0:\n",
    "        num_valid_elements = 1\n",
    "    res = {}\n",
    "    for key, value in output.items():\n",
    "        res[key] = value[:num_valid_elements]\n",
    "    return res\n",
    "\n",
    "def format_for_submission(output:dict) -> str:\n",
    "    \"\"\"\n",
    "    this method is responsible for formatting output so that it fits a submission format\n",
    "    \"\"\"\n",
    "    output = slice_output(output)\n",
    "    res_str = ''\n",
    "    for bbox, score in zip(output['boxes'], output['scores']):\n",
    "        # print(bbox, score)\n",
    "        w = bbox[2] - bbox[0]\n",
    "        h = bbox[1] - bbox[3]\n",
    "        x = bbox[0]\n",
    "        y = bbox[1]\n",
    "        res_str += '{} {} '.format(score, ''.join(map(str, [x, y, w, h])))\n",
    "    return res_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83e732bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T10:32:34.365161Z",
     "iopub.status.busy": "2022-01-19T10:32:34.364121Z",
     "iopub.status.idle": "2022-01-19T10:32:39.034778Z",
     "shell.execute_reply": "2022-01-19T10:32:39.035315Z",
     "shell.execute_reply.started": "2022-01-19T10:31:18.197090Z"
    },
    "papermill": {
     "duration": 4.685295,
     "end_time": "2022-01-19T10:32:39.035533",
     "exception": false,
     "start_time": "2022-01-19T10:32:34.350238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 2  # starfish and not starfish I guess\n",
    "\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained_backbone=False)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "# load trained model\n",
    "model.load_state_dict(torch.load('/kaggle/input/modelsmall/model2.pt', map_location=torch.device('cpu')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11b7e7aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T10:32:39.055492Z",
     "iopub.status.busy": "2022-01-19T10:32:39.054774Z",
     "iopub.status.idle": "2022-01-19T10:32:56.674170Z",
     "shell.execute_reply": "2022-01-19T10:32:56.674767Z",
     "shell.execute_reply.started": "2022-01-19T10:31:22.081456Z"
    },
    "papermill": {
     "duration": 17.63398,
     "end_time": "2022-01-19T10:32:56.674992",
     "exception": false,
     "start_time": "2022-01-19T10:32:39.041012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/kaggle/input/tensorflow-great-barrier-reef')\n",
    "import greatbarrierreef\n",
    "env = greatbarrierreef.make_env()   # initialize the environment\n",
    "iter_test = env.iter_test()    # an iterator which loops over the test set and sample submission\n",
    "with torch.no_grad():\n",
    "\n",
    "    for (pixel_array, sample_prediction_df) in iter_test:\n",
    "\n",
    "        img = torch.from_numpy(pixel_array)\n",
    "        img = torch.permute(img, (2, 0, 1))\n",
    "        min_image = img.min()\n",
    "        max_image = img.max()\n",
    "        # normalize image to 0-1 - required by torchvision\n",
    "        img -= min_image\n",
    "        img = torch.FloatTensor(img/max_image)\n",
    "        img = torch.unsqueeze(img, 0) # add dummy batch dimension\n",
    "        model.eval()\n",
    "        output = model(img)\n",
    "        result = format_for_submission(output[0])\n",
    "#         print(result)\n",
    "        sample_prediction_df['annotations'] = result  # make your predictions here\n",
    "        env.predict(sample_prediction_df)   # register your predictions\n",
    "    sample_prediction_df.to_csv('/kaggle/working/submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 45.763331,
   "end_time": "2022-01-19T10:33:00.062785",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-01-19T10:32:14.299454",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}